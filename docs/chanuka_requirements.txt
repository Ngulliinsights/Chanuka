# Chanuka Platform Consolidation Requirements Document

## Document Control
- **Project**: Chanuka Civic Engagement Platform
- **Document Type**: Requirements Specification (Enhanced EARS)
- **Version**: 1.0
- **Status**: Draft for Review
- **Date**: 2024-11-27

## Executive Summary

This requirements document specifies the consolidation and refactoring work needed to transform the Chanuka platform from its current state of architectural fragmentation to a clean, maintainable codebase ready for production deployment. The primary objective is to eliminate redundancy, establish clear canonical patterns, and improve development velocity while preserving all existing functionality and maintaining backward compatibility throughout the transition.

---

## R1: Structural Hygiene and Artifact Removal

**User Story**: As a developer working on the Chanuka platform, I want all crisis artifacts and temporary files removed from the codebase, so that I can navigate the project structure without confusion and focus on active development rather than archaeological investigation.

WHEN a developer examines any directory in the project THEN the system SHALL contain only active, production-relevant files WHERE no timestamp-versioned configuration files, backup directories, or emergency fix scripts exist in the working tree.

**Acceptance Criteria**:

1. WHEN the project root is scanned for timestamp-versioned files THEN the system SHALL identify zero files matching the pattern `*.timestamp-*` WHERE all such files have been permanently removed from the working directory and Git history has been preserved for reference.

2. WHEN any directory is examined for backup artifacts THEN the system SHALL contain zero directories with `.backup` suffix and zero files with `.backup` extension WHERE all backup content has been either integrated into canonical implementations or archived to `docs/completed-work/archive/`.

3. WHEN the scripts directory is audited THEN the system SHALL contain zero files with names indicating emergency interventions (matching patterns like `emergency-*`, `super-aggressive-*`, `fix-critical-*`) WHERE such scripts have been either converted into permanent utilities with proper documentation or removed entirely.

4. WHEN the logs directory is checked in version control THEN the system SHALL show logs/ in .gitignore and contain zero committed log files WHERE any previously committed logs have been purged from Git history using filter-branch or BFG Repo-Cleaner.

5. WHEN markdown documentation files about fixes and migrations are located THEN the system SHALL find all such files in `docs/completed-work/` rather than scattered through source directories WHERE files like BUILD_FIX_SUMMARY.md, MIGRATION_SUMMARY.md are consolidated in one archival location.

6. WHEN multiple versions of the same configuration exist (such as main.tsx, main-restored.tsx, main-simple.tsx) THEN the system SHALL contain exactly one canonical version WHERE alternative implementations have been removed and the decision is documented in ARCHITECTURE.md.

---

## R2: Database Access Standardization Through Repository Interfaces

**User Story**: As a backend developer implementing features, I want all database access to go through well-defined repository interfaces, so that I can query data without coupling to specific database technologies and the platform can migrate to Neo4j without rewriting feature code.

WHEN any feature needs to access persistent data THEN the system SHALL provide that access exclusively through repository interfaces defined in `server/domain/interfaces/` WHERE no feature code directly imports database connection managers, ORM libraries, or executes raw queries.

**Acceptance Criteria**:

1. WHEN the bills feature needs to query bill data THEN the system SHALL provide an IBillRepository interface with methods like `findById(id: string): Promise<Bill>`, `findByStatus(status: BillStatus): Promise<Bill[]>`, `save(bill: Bill): Promise<void>` WHERE the interface contains all query patterns currently used across the application.

2. WHEN the repository interface is implemented for Drizzle ORM THEN the system SHALL contain the implementation in `server/infrastructure/persistence/drizzle/DrizzleBillRepository.ts` WHERE all SQL-specific logic, connection management, and query construction is isolated in the infrastructure layer.

3. WHEN feature code needs a repository instance THEN the system SHALL receive it through dependency injection at the service/use-case level WHERE features declare their dependencies as constructor parameters typed to repository interfaces, not concrete implementations.

4. WHEN multiple database connection approaches currently exist (`shared/database/core/connection-manager.ts`, `server/infrastructure/database/connection-pool.ts`, `server/db.ts`) THEN the system SHALL consolidate all connection logic into infrastructure layer implementations WHERE connection details are hidden behind repository interfaces.

5. WHEN the codebase is scanned for direct Drizzle imports in feature code THEN the system SHALL find zero such imports in `server/features/*/application/` or `server/features/*/domain/` WHERE only infrastructure layer and repository implementations import ORM-specific modules.

6. WHEN a new data access method is needed THEN the system SHALL require adding the method signature to the appropriate repository interface before implementation WHERE interface changes are reviewed for their impact on future Neo4j migration.

---

## R3: Search System Consolidation to PostgreSQL Full-Text

**User Story**: As a platform operator, I want a single, well-optimized search implementation for the initial launch, so that I can maintain search functionality efficiently without the complexity of multiple search engines until user scale justifies additional sophistication.

WHEN a user performs a search query THEN the system SHALL execute that search using PostgreSQL full-text search exclusively WHERE Fuse.js and semantic search engines are disabled in production but remain in the codebase for future activation.

**Acceptance Criteria**:

1. WHEN the search feature is invoked in production THEN the system SHALL route all queries through `server/features/search/engines/core/postgresql-fulltext.engine.ts` WHERE the routing decision is controlled by a feature flag in `server/infrastructure/feature-flags.ts`.

2. WHEN Fuse.js or semantic search engines exist in the codebase THEN the system SHALL mark them with clear comments indicating "EXPERIMENTAL - Not active in production. See docs/search-strategy.md for activation criteria" WHERE the code remains compilable and testable but is unreachable through production code paths.

3. WHEN search-related test suites are executed THEN the system SHALL primarily test PostgreSQL full-text search with comprehensive coverage WHERE alternative engine tests are marked as integration tests for future use and excluded from the critical path test suite.

4. WHEN search infrastructure requires maintenance or optimization THEN the system SHALL focus effort exclusively on the PostgreSQL implementation WHERE query performance, index management, and relevance tuning target a single engine.

5. WHEN search analytics are collected THEN the system SHALL track metrics for PostgreSQL search performance (query time, result relevance, user engagement) WHERE these metrics establish baselines for evaluating when alternative engines might be beneficial.

6. WHEN documentation describes the search system THEN the system SHALL clearly state the production search strategy and criteria for introducing additional engines WHERE the documentation in `docs/search-strategy.md` explains that multi-engine search is deferred until PostgreSQL shows measurable inadequacy at scale.

---

## R4: Frontend Component Organization via Feature-Sliced Design

**User Story**: As a frontend developer, I want a clear, unambiguous location for every component based on its usage scope, so that I can create new components efficiently and understand component dependencies without investigating multiple potential locations.

WHEN a developer creates a new UI component THEN the system SHALL enforce placement rules based on feature scope WHERE components used by a single feature live in that feature's directory and only genuinely shared components exist in shared directories.

**Acceptance Criteria**:

1. WHEN a component is used exclusively within the bills feature THEN the system SHALL locate that component in `client/src/features/bills/ui/` WHERE the component imports and uses only dependencies available to the bills feature scope.

2. WHEN a component is initially created as shared but analysis shows single-feature usage THEN the system SHALL move that component from `client/src/shared/ui/` or `client/src/components/` to the appropriate feature directory WHERE component movement is tracked in migration documentation.

3. WHEN a component genuinely serves multiple features (proven by import analysis showing 3+ distinct feature imports) THEN the system SHALL promote it to `client/src/shared/ui/` WHERE the promotion decision is documented with usage patterns justifying the shared status.

4. WHEN the design system provides primitive components (buttons, inputs, cards) THEN the system SHALL locate these in `client/src/shared/design-system/` WHERE these components have zero feature-specific logic and serve purely as styled HTML element wrappers.

5. WHEN the client source tree is analyzed for component locations THEN the system SHALL show clear organizational hierarchy: feature-specific in features/[feature]/ui/, cross-feature in shared/ui/, primitives in shared/design-system/ WHERE the generic `client/src/components/` directory is deprecated and empty except for layout components.

6. WHEN import statements reference components THEN the system SHALL enforce that feature code cannot import from other features' ui directories (enforced via ESLint rules) WHERE only shared components are importable across feature boundaries.

---

## R5: Security Policy Centralization with Distributed Enforcement

**User Story**: As a security auditor, I want all security policies defined in a single, reviewable location while enforcement remains appropriately distributed, so that I can verify security posture comprehensively without creating implementation bottlenecks.

WHEN security policies are defined or modified THEN the system SHALL maintain those definitions exclusively in `shared/core/src/security/policies/` WHERE policy modules export configuration objects and validation functions consumed by enforcement points.

**Acceptance Criteria**:

1. WHEN rate limiting rules are specified THEN the system SHALL define all rate limit configurations in `shared/core/src/security/policies/rate-limits.ts` with schema like `{ endpoint: string, limit: number, window: string, keyGenerator: Function }` WHERE enforcement middleware consumes these policies without containing policy logic itself.

2. WHEN Content Security Policy headers are configured THEN the system SHALL define CSP rules in `shared/core/src/security/policies/csp.ts` WHERE the policy module exports CSP directives as structured data consumed by security header middleware.

3. WHEN input validation rules are established THEN the system SHALL define validation schemas in `shared/core/src/security/policies/validation-schemas.ts` WHERE validation logic uses these schemas at API boundaries without duplicating rule definitions.

4. WHEN authentication requirements are specified for routes THEN the system SHALL define auth policies in `shared/core/src/security/policies/authentication.ts` with patterns like `{ routes: string[], requiredRoles: Role[], mfaRequired: boolean }` WHERE route guards consume these policies.

5. WHEN security policies are enforced THEN the system SHALL implement enforcement in appropriate middleware layers (API gateway for rate limiting, route handlers for authentication, input validation at controller boundaries) WHERE enforcement code references centralized policies but remains distributed for performance.

6. WHEN security policies are audited THEN the system SHALL enable review of all security rules by examining the policies directory exclusively WHERE any security rule not defined in this directory is flagged as a policy violation during code review.

---

## R6: Test Infrastructure Unification

**User Story**: As a developer running tests, I want a single test command with clear options for test types, so that I can run relevant test suites efficiently without managing multiple configuration files or remembering different command patterns.

WHEN a developer executes the test suite THEN the system SHALL provide a unified test runner with filtering options WHERE a single vitest.config.ts supports all test types through project references rather than separate configuration files.

**Acceptance Criteria**:

1. WHEN the test command is invoked with `npm test` THEN the system SHALL execute unit tests by default WHERE the configuration in `vitest.config.ts` defines a "unit" project that runs tests matching `**/*.test.ts` excluding integration and e2e patterns.

2. WHEN integration tests are requested with `npm test:integration` THEN the system SHALL execute only integration tests WHERE the same `vitest.config.ts` defines an "integration" project with appropriate setup files and test patterns matching `**/*.integration.test.ts`.

3. WHEN end-to-end tests are executed with `npm test:e2e` THEN the system SHALL run Playwright tests WHERE a single `playwright.config.ts` defines multiple projects for different browsers and devices without duplicate configuration.

4. WHEN performance tests are needed with `npm test:performance` THEN the system SHALL execute performance benchmarks WHERE the "performance" project in vitest.config.ts has extended timeouts and specialized reporters.

5. WHEN all tests are executed with `npm test:all` THEN the system SHALL run all test projects sequentially WHERE the command orchestrates unit → integration → e2e → performance with appropriate setup and teardown between stages.

6. WHEN the test infrastructure is examined THEN the system SHALL contain exactly one vitest.config.ts and one playwright.config.ts at the root WHERE separate config files like vitest.integration.config.ts, vitest.performance.config.ts have been consolidated into the single config using project references.

---

## R7: Module Boundary Enforcement and Dependency Management

**User Story**: As an architect maintaining system integrity, I want strict enforcement of module boundaries with explicit dependency rules, so that the client, shared, and server modules remain properly decoupled and unintended dependencies cannot be introduced accidentally.

WHEN code is committed to the repository THEN the system SHALL enforce dependency rules through automated linting WHERE violations of module boundaries are caught before merge and prevent build completion.

**Acceptance Criteria**:

1. WHEN client code is analyzed for imports THEN the system SHALL verify that client modules import only from client/, shared/, and node_modules WHERE any import from server/ triggers a linting error with message "Client cannot depend on server code. Move shared logic to shared/ module."

2. WHEN server code is analyzed for imports THEN the system SHALL verify that server modules import only from server/, shared/, and node_modules WHERE server code has no visibility into client-specific modules.

3. WHEN shared code is analyzed for imports THEN the system SHALL verify that shared modules import only from other shared modules and node_modules WHERE shared code cannot import from client/ or server/ to prevent circular dependencies.

4. WHEN a feature module is examined THEN the system SHALL verify that features import from shared/ only through well-defined public APIs (index.ts exports) WHERE internal implementation details of shared modules are not importable by features.

5. WHEN module boundaries are configured THEN the system SHALL define these rules in `.eslintrc.js` using the `import/no-restricted-paths` plugin WHERE the configuration explicitly lists allowed and forbidden import patterns for each module.

6. WHEN continuous integration runs THEN the system SHALL include a "lint:dependencies" step that specifically checks module boundary rules WHERE this step runs before tests and provides clear violation reports indicating which imports violate boundaries and how to fix them.

---

## R8: Canonical Pattern Documentation and Architectural Decision Records

**User Story**: As a developer joining the project or returning after absence, I want clear, authoritative documentation of architectural patterns and decisions, so that I can understand which approaches to use without archaeological investigation or guessing from inconsistent examples.

WHEN a developer needs to understand how to implement common tasks THEN the system SHALL provide that guidance in an ARCHITECTURE.md file at the repository root WHERE the document specifies canonical patterns for database access, API endpoints, component creation, testing, and error handling.

**Acceptance Criteria**:

1. WHEN the repository is cloned THEN the system SHALL include an ARCHITECTURE.md file in the root directory WHERE this file is the single source of truth for architectural decisions and is maintained as code through standard PR review.

2. WHEN a developer needs to know how to access data THEN the ARCHITECTURE.md SHALL specify "All database access goes through repository interfaces in server/domain/interfaces/. Example: See server/features/bills/ for reference implementation" WHERE the guidance includes concrete examples from the actual codebase.

3. WHEN a developer needs to create a new feature THEN the ARCHITECTURE.md SHALL specify "New features follow the structure in server/features/bills/ with domain/, application/, infrastructure/, and presentation/ layers" WHERE the document explains what belongs in each layer with examples.

4. WHEN architectural decisions are made during development THEN the system SHALL require updates to ARCHITECTURE.md as part of the PR WHERE significant architectural changes cannot be merged without corresponding documentation updates.

5. WHEN conflicting implementation patterns exist THEN the ARCHITECTURE.md SHALL explicitly deprecate old patterns and specify migration paths WHERE the document states "Legacy patterns in server/controllers/ are deprecated. Do not extend. New features use server/features/ structure."

6. WHEN the architecture document is reviewed THEN the system SHALL organize content hierarchically: Quick Start → Core Concepts → Module Boundaries → Data Access → API Design → Frontend Organization → Testing Strategy → Security → Migration Guides WHERE each section provides both principles and practical examples.

---

## R9: Progressive Migration Strategy with Feature Flags

**User Story**: As a product manager concerned about deployment risk, I want all consolidation work to happen incrementally with feature flags controlling new implementations, so that we can migrate safely without big-bang deployments and can roll back instantly if issues arise.

WHEN consolidation work creates new implementations of existing functionality THEN the system SHALL deploy both old and new implementations simultaneously with feature flags controlling which is active WHERE the flag system allows instant rollback without code deployment.

**Acceptance Criteria**:

1. WHEN database repository interfaces are introduced THEN the system SHALL support a feature flag `use_repository_pattern` that routes data access through either new repository interfaces or legacy direct queries WHERE the flag defaults to false initially and is gradually rolled out.

2. WHEN search consolidation moves from multi-engine to PostgreSQL-only THEN the system SHALL provide a feature flag `search_engine_selection` that chooses between "postgresql", "fuse", or "semantic" WHERE PostgreSQL becomes default only after validation period.

3. WHEN frontend components are reorganized THEN the system SHALL use conditional imports or dynamic loading that respects feature flags WHERE old component locations remain functional during transition period.

4. WHEN feature flags are configured THEN the system SHALL store configuration in `server/infrastructure/feature-flags.ts` with environment variable overrides WHERE flags can be toggled without redeployment through environment variables.

5. WHEN migration progress is tracked THEN the system SHALL maintain a migration dashboard accessible at `/admin/migrations` (authenticated) WHERE the dashboard shows which features use new patterns, feature flag states, and rollback procedures.

6. WHEN a consolidated feature is validated THEN the system SHALL follow a deprecation process: flag enabled for 10% traffic → 50% → 100% → old code removed after 2 weeks of 100% WHERE telemetry confirms new implementation matches old behavior before old code removal.

---

## R10: Validation and Safety Mechanisms

**User Story**: As a technical leader responsible for platform stability, I want comprehensive validation mechanisms that ensure refactoring work preserves all existing functionality, so that consolidation improves structure without introducing regressions or data loss.

WHEN refactoring work is performed THEN the system SHALL execute validation tests comparing old and new implementation behaviors WHERE tests confirm functional equivalence before old implementations are removed.

**Acceptance Criteria**:

1. WHEN repository interfaces replace direct database queries THEN the system SHALL include comparison tests that execute the same operations through both approaches and assert identical results WHERE tests cover all CRUD operations, edge cases, and error conditions.

2. WHEN search consolidation is deployed THEN the system SHALL log both PostgreSQL and legacy search results for a sample of queries WHERE logs are analyzed for result divergence and unexpected behavior before legacy code removal.

3. WHEN frontend components are reorganized THEN the system SHALL include visual regression tests using Playwright that capture screenshots of key user journeys WHERE screenshots before and after reorganization are pixel-compared for differences.

4. WHEN module boundaries are enforced THEN the system SHALL build successfully on a clean checkout WHERE the build process verifies that all imports resolve and no circular dependencies exist.

5. WHEN security policy centralization is implemented THEN the system SHALL include audit tests that verify all security enforcement points reference centralized policies WHERE tests fail if any endpoint implements security logic without consuming shared policies.

6. WHEN consolidation work is considered complete THEN the system SHALL pass a comprehensive validation suite including: all existing tests passing, bundle size not increasing more than 5%, no new console errors or warnings, all API endpoints returning expected responses, database query patterns unchanged WHERE this validation suite gates production deployment.

---

## Requirements Traceability Matrix

| Requirement ID | Category | Priority | Risk Level | Dependencies | Validation Method |
|---------------|----------|----------|------------|--------------|-------------------|
| R1 | Infrastructure | High | Low | None | Automated script verification |
| R2 | Architecture | Critical | Medium | R1 | Unit + Integration tests |
| R3 | Performance | High | Low | R2 | Performance benchmarks |
| R4 | Architecture | High | Low | R1 | Import analysis + Linting |
| R5 | Security | Critical | Medium | R1, R4 | Security audit tests |
| R6 | Infrastructure | Medium | Low | R1 | CI/CD pipeline tests |
| R7 | Architecture | Critical | Low | R4 | Linting + Build verification |
| R8 | Documentation | High | Low | All | Documentation review |
| R9 | Process | Critical | Medium | R2, R3, R4, R5 | Feature flag testing |
| R10 | Quality | Critical | High | All | Comprehensive validation suite |

---

## Success Criteria

The consolidation project shall be considered successful when all of the following conditions are met:

1. Zero architectural debt files remain in the repository (no timestamp files, backups, or emergency fixes)
2. All feature code accesses data through repository interfaces with zero direct database imports
3. PostgreSQL full-text search handles 100% of production search traffic with response times under 200ms for the 95th percentile
4. Frontend component organization follows Feature-Sliced Design with zero components in deprecated locations
5. Security policies are centralized with audit tests confirming all enforcement points reference shared policies
6. Test suite executes through unified configuration with clear documentation of test types
7. Module boundary enforcement prevents cross-boundary imports with zero linting violations
8. ARCHITECTURE.md document is complete, reviewed, and accepted as canonical reference
9. All feature flags have been evaluated, with consolidated implementations serving 100% of traffic
10. Comprehensive validation suite passes with zero regressions from pre-consolidation baseline
